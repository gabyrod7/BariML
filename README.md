# BariML
## Introduction
An introduction to fully connected deep neural networks (DNN) and convolutional neural networks (CNN) in which their mathematical underpinning is explained. Machine learning (ML) models are mathematical functions that happen to be much more complicated than the ones typically found in textbooks for cientists and engineers. The exponential growth in ML-based applications is due, in part, to four breakthroughs. The first is the current ability to fit enormously complicated functions to data, something that was technologically impossible at the start of the century. The second is the ability to use huge data sets for fitting these models. The third is the discovery that these complicated functions can mimic behavior associated with intelligence and last but not least is the invention by machine learning researchers of highly expressive models and very effective fitting methods.

Much of the work in the machine learning community has indeed been, and continues to be, extremely creative. But, all too often, when described, machine learning models come across as mysterious and inscrutable. In part this is because of the highly suggestive jargon that permeates machine learning. For example, the word "learning" is misleading. Learning, as ordinarily understood, implies understanding. But can it really be said that a mathematical function, even one with tens of millions of parameters understands? The answer, at the very least,  is unclear.

## Setup
### 1. Download this package:
```bash
git clone https://github.com/hbprosper/BarML
```
