{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn: Classification - 2\n",
    " >__Created__:  2018 Harrison B. Prosper\n",
    "\n",
    "\n",
    "## Introduction\n",
    "We consider the benchmark task of classifying the $28 \\times 28 = 784$ gray scale pixel images of handwritten digits in the MNIST data set using __supervised learning__. In supervised learning a model is trained (that is, fitted) to data consisting of unambiguously labeled __feature vectors__, here images. For classification the label is the class to which a vector belongs, while for regression the labels are the values associated with the vectors. In the MNIST data set there are $K = 10$ classes, labeled by the digits 0 to 9. The data contains $T = 60,000$ images for training and 10,000 images for testing. Following good practice, we split the training data into a set for training and another for validating the training. The test data are not used in the training.\n",
    "\n",
    "The value of each pixel in the MNIST data set lies in the discrete set $[0, 1, \\cdots, 255]$. Again, following good practice, we rescale each datum so that it lies in the unit interval. In this exercise, the data lie in the (rational) set $D = [0, 1/255, \\cdots, 1]$. The MNIST training data is to be thought of as a sample from some unknown probability distribution $p(t, x)$ defined on the finite discrete space $[0,\\cdots,9] \\times D^{784}$, where the __target__, $t$, is the class label associated with image $x$. ($p(t, x)$ is clearly an abstraction since it is the distribution of an infinite MNIST data set that exists only in the same sense as the set of real numbers.) An image can be conceptualized as a point $x \\in D^{784}$. If we associate each class with a different color, the training data form a swarm of colored points where points of a given color tend to \"flock\" together.\n",
    "\n",
    "In this exercise, a fully connected shallow neural network (SNN) is used to classify the MNIST digits. The training is done with __batches__ of images represented by a 2-index tensor $\\mathbf{x}_{nj}$ of __shape__ $(N, H \\times W)$, i.e., a matrix. The first index (along dimension dim = 0) labels the ordinal value $n$ of an image in a batch of $N$ images, while the second index (along dim = 1) labels the pixels of a *flattened* image of height and width $H$ and $W$, respectively.  \n",
    "\n",
    "### Model\n",
    "Machine learning models often have an aura of mystery about them. But, a sensible perspective can be maintained by remembering that regardless of how their form may have been motivated, these models are, ultimately, just exceedingly complicated non-linear functions. \n",
    "\n",
    "Another point should be noted before we delve into details. Much has been made of the sometimes spectacular failure in the application of machine learning to real-world problems. For example, suppose that a single pixel in an image is changed, say from the value 197/255 to the value 0. This causes the point representing the image in the space $D^{784}$ to suffer a displacement in that space. To the human brain, a single pixel change in a $28 \\times 28$ image is a negligible distortion that does not impair its ability to classify the image, either because the distortion goes unnoticed or it is ignored. But, to a machine learned classifier, a single pixel change could result in a large displacement in the abstract space of images, thereby making the image an outlier whose position is no longer representative of the distribution of *any* of the classes defined by the probability $p(t, x)$. The point is that the classifier depends on the probability $p(t, x)$, therefore, if the latter fails to capture the kinds of outliers one expects in real-world data, it ought not to surprise that the classifier may fail to classify an outlier correctly. \n",
    "\n",
    "One might think that the solution is to train with data that contains outliers. However, it may not be feasible to build a model that captures every sort of potential outlier. Moreover, if outliers in the training data are relatively rare, the training procedure may simply ignore them. A more practical approach might be to devise a way to recognize when an image is an outlier, detect which subsets of pixels are responsible for this and assign to the offending pixels values that are representative of their neighborhood. Having tamed the image in this way, it is then presented to the classifier.\n",
    "\n",
    "In this exercise, we use the following model \n",
    "\n",
    "$$\\mathbf{y} = \\mbox{softmax}(\\,\\mathbf{b}_1 + \\mathbf{w}_1 \\, \\mbox{relu}(\\mathbf{b}_0 + \\mathbf{w}_0 \\, \\mathbf{x}) \\, ),$$\n",
    "\n",
    "where $\\mathbf{b}$ and $\\mathbf{w}$, the biases and weights, are the parameters of the model and $\\mbox{relu}(x)$, which is applied to every element $x$ of its tensor argument (i.e., applied element-wise), is defined by\n",
    "\n",
    "\\begin{align*}\n",
    "\\mbox{relu}(x) & = \\begin{cases}\n",
    "    x, & \\text{if } x \\gt 0\\\\\n",
    "    0              & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "The parameters with suffix 0 pertain to the input layer, while those with suffix 1 pertain to the so-called __hidden__ layer.\n",
    "Since $\\mathbf{y}$ models class probabilities that sum to unity, it makes sense to map each output of the hidden layer to the unit interval by applying, for example, the softmax function for $K$ output classes, \n",
    "\n",
    "\\begin{align*}\n",
    "(\\mbox{softmax}(x))_k & = \\frac{\\exp(x_{(k)})}{\\sum_{j=0}^{K-1} \\exp(x_{(j)})} ,\n",
    "\\end{align*}\n",
    "\n",
    "where $x_{(k)}$ denotes the $k^\\mbox{th}$ output of the hidden layer. \n",
    "\n",
    "### Loss function\n",
    "Typically, a machine learning model is fitted to the training data by minimizing a suitably defined function, which in the statistics literature is often referred to as the __empirical risk__. (Fitting models to data is called learning by machine learning enthusiasts.) The empirical risk is a Monte Carlo approximation of the __risk functional__, defined by \n",
    "\n",
    "\\begin{align*}\n",
    "    R[f] &= \\int L(t, \\, f(x, \\theta)) \\, \n",
    "    p(t, \\, x) \\, dt \\, dx,\n",
    "\\end{align*}\n",
    "\n",
    "where $L(t, \\, f)$ is called the __loss function__ and measures how much one loses if the output of the parameterized function $f(x, \\theta)$ differs from the __target__ $t$. $\\color{blue}{\\rm Warning}$: In the machine learning world, the empirical risk is typicaly referred to as the loss function, when what is really meant is the average loss function. \n",
    "\n",
    "__Important Note__: In order for the risk functional $R[f]$ to reach its minimum, defined by variations of $f$ that yield the condition $\\delta R = 0$ for all $x$, the function $f$ must be sufficiently flexible. If the latter condition is satisfied, then the mathematical quantity approximated by $f$ depends solely on the form of the loss function $L(t, \\, f)$ and the probability distribution $p(t, \\, x)$ of the training data. In particular, it does not depend on\n",
    "    the details of the functon $f$ apart from its presumed flexibility. Of course, in practice, we do not minimize $R[f]$, but rather the empirical risk, which is an approximation to it. Nevertheless, to the degree that a very large data set approximates an infinite one and to the degree that our minimizer is able to find a good minimum, this note suggests it is as least as important to think about the form of the loss function $L(t, \\, f)$ as it is to think about the form of the model. After all, if we have two models of equal functional flexibility, *a priori*, for the same loss function thet will approximate the same quantity. \n",
    "\n",
    "In order to motivate our choice of loss function, we start with the __Kullback-Leibler__ (KL) divergence\n",
    "\n",
    "\\begin{align*}\n",
    "    D(p || q) & = \\sum_i p_i \\log(p_i / q_i),\n",
    "\\end{align*}\n",
    "\n",
    "which is a *global* measure of the dissimilarity between a probability distribution $p$ and a reference distribution $q$. The KL divergence is a global measure in that it depends on the entire probability distributions $p$ and $q$. In particular, the measure does not supply information about where $p$ and $q$ are well matched and where they are not. \n",
    "\n",
    "The KL divergence is zero if and only if the two distributions are identical. Typically, we have a model for $q$, but $p$ is usually unknown, which makes it difficult to approximate $D(p || q)$. However, the KL divergence can be written as,\n",
    "\n",
    "\\begin{align*}\n",
    "  D(p || q) & = \\sum_i p_i \\log(p_i / q_i),\\\\\n",
    "            & = -\\sum_i p_i \\log q_i - \\left(-\\sum_i p_i \\log p_i\\right),\\\\\n",
    "            & = H(p, q) - H(p).\n",
    "\\end{align*}\n",
    "\n",
    "The quantity $H(p) = -\\sum_i p_i \\log p_i$ is called the __entropy__, while $H(p, q)$ is called the __cross entropy__. Like the KL divergence, the cross entropy is minimized when $q = p$, whereupon it equals the entropy of the probability distribution $p$. The practical advantage of the cross entropy over the KL divergence is that for training data distributed according to $p$, we can use the following Monte Carlo approximation of the cross entropy,\n",
    "\n",
    "\\begin{align*}\n",
    "  H(p, q) & = -\\sum_i p_i \\log q_i,\\\\\n",
    "            & \\approx -\\frac{1}{T}\\sum_{i=0}^{T-1} \\log q_i,\n",
    "\\end{align*}\n",
    "\n",
    "where $T$ is the number of feature vectors, here images, in the training set. In this exercise, we shall use cross entropy as the loss function.\n",
    "The outputs of the model are the conditional class probabilities\n",
    "\n",
    "\\begin{align*}\n",
    "    P(k \\, | \\, \\mathbf{x} ) & = \\frac{P(\\mathbf{x} \\, | \\, k) \\, \\pi(k)}{\\sum_{j=0}^K P(\\mathbf{x} \\, | \\, j) \\, \\pi(j)},\n",
    "\\end{align*}\n",
    "\n",
    "where $\\pi(k)$ is the prior probability of class $k$ and $P(\\mathbf{x} \\, | \\, k)$ is the probability of image $\\mathbf{x}$ *given* that it is of class $k$. ($P(\\mathbf{x} \\, | \\, k)$ is often referred to as the __likelihood__.) To compute the loss function, we set $q_i = P(k_i \\, | \\, \\mathbf{x}_i )$, where $k_i$ is the true class index of image $x_i$. In other words, we take $q_i$ to be the estimated conditional probability that image $x_i$ is of class $k_i$ given that it is known to be of that class.\n",
    "\n",
    "### Exercise\n",
    "  1. Build deep network, using __MLPClassifier__, to classifier handwritten digits from the MNIST database \n",
    "  1. Try one and two hidden layers.\n",
    "  1. Vary the number of nodes/layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry/miniconda2/envs/python3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "try:\n",
    "    from joblib import joblib\n",
    "except:\n",
    "    from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update fonts\n",
    "FONTSIZE = 16\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : FONTSIZE}\n",
    "\n",
    "mp.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load MNIST data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = joblib.load('../datasets/mnist_train.pkl')\n",
    "test_x,  test_y  = joblib.load('../datasets/mnist_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a selection of images from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(x, n_rows=2, n_cols=5, f_size=(10, 4)):\n",
    "    f, ax = plt.subplots(nrows=n_rows, \n",
    "                         ncols=n_cols, \n",
    "                         figsize=f_size)\n",
    "    \n",
    "    for image, ax in zip(x, ax.flatten()):\n",
    "        ax.imshow(image.reshape(28, 28), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotImages(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TRAINING ***\n",
      "Iteration 1, loss = 0.40732814\n",
      "Iteration 2, loss = 0.16113032\n",
      "Iteration 3, loss = 0.11865388\n",
      "Iteration 4, loss = 0.09465947\n",
      "Iteration 5, loss = 0.08134931\n",
      "Iteration 6, loss = 0.06974821\n",
      "Iteration 7, loss = 0.06211915\n",
      "Iteration 8, loss = 0.05386695\n",
      "Iteration 9, loss = 0.04940621\n",
      "Iteration 10, loss = 0.04579688\n",
      "Iteration 11, loss = 0.04139810\n",
      "Iteration 12, loss = 0.03826757\n",
      "Iteration 13, loss = 0.03579057\n",
      "Iteration 14, loss = 0.03323018\n",
      "Iteration 15, loss = 0.03221626\n",
      "Iteration 16, loss = 0.03069390\n",
      "Iteration 17, loss = 0.02997901\n",
      "Iteration 18, loss = 0.02891849\n",
      "Iteration 19, loss = 0.02865835\n",
      "Iteration 20, loss = 0.02657874\n",
      "Iteration 21, loss = 0.02576001\n",
      "Iteration 22, loss = 0.02510506\n",
      "Iteration 23, loss = 0.02919860\n",
      "Iteration 24, loss = 0.02726567\n",
      "Iteration 25, loss = 0.02483873\n",
      "Iteration 26, loss = 0.02214253\n",
      "Iteration 27, loss = 0.02429505\n",
      "Iteration 28, loss = 0.02801485\n",
      "Iteration 29, loss = 0.02931947\n",
      "Iteration 30, loss = 0.02459416\n",
      "Iteration 31, loss = 0.02022567\n",
      "Iteration 32, loss = 0.01983291\n",
      "Iteration 33, loss = 0.01824823\n",
      "Iteration 34, loss = 0.01965700\n",
      "Iteration 35, loss = 0.03620236\n",
      "Iteration 36, loss = 0.02939857\n",
      "Iteration 37, loss = 0.02277252\n",
      "Iteration 38, loss = 0.01975091\n",
      "Iteration 39, loss = 0.01779865\n",
      "Iteration 40, loss = 0.01750619\n",
      "Iteration 41, loss = 0.03261471\n",
      "Iteration 42, loss = 0.02672472\n",
      "Iteration 43, loss = 0.02510558\n",
      "Iteration 44, loss = 0.02058444\n",
      "Iteration 45, loss = 0.01825692\n",
      "Iteration 46, loss = 0.01767634\n",
      "Iteration 47, loss = 0.02660037\n",
      "Iteration 48, loss = 0.03024324\n",
      "Iteration 49, loss = 0.02386810\n",
      "Iteration 50, loss = 0.01922325\n",
      "Iteration 51, loss = 0.01733406\n",
      "Iteration 52, loss = 0.01656595\n",
      "Iteration 53, loss = 0.01600270\n",
      "Iteration 54, loss = 0.01569801\n",
      "Iteration 55, loss = 0.03318484\n",
      "Iteration 56, loss = 0.02908163\n",
      "Iteration 57, loss = 0.02092153\n",
      "Iteration 58, loss = 0.01785744\n",
      "Iteration 59, loss = 0.01663285\n",
      "Iteration 60, loss = 0.01597876\n",
      "Iteration 61, loss = 0.01541333\n",
      "Iteration 62, loss = 0.02154398\n",
      "Iteration 63, loss = 0.03782604\n",
      "Iteration 64, loss = 0.02324017\n",
      "Iteration 65, loss = 0.01814573\n",
      "Iteration 66, loss = 0.01666874\n",
      "Iteration 67, loss = 0.01624085\n",
      "Iteration 68, loss = 0.01572053\n",
      "Iteration 69, loss = 0.01589690\n",
      "Iteration 70, loss = 0.03363957\n",
      "Iteration 71, loss = 0.02465224\n",
      "Iteration 72, loss = 0.01826202\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n",
      "Training set score: 0.999883\n",
      "Test set score:     0.981200\n",
      "save to mnist_scikit_snn.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mnist_scikit_snn.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100), \n",
    "                    max_iter=1000, \n",
    "                    alpha=1e-2,\n",
    "                    solver='adam', \n",
    "                    verbose=1, \n",
    "                    tol=1e-6, \n",
    "                    warm_start=False,\n",
    "                    random_state=1)\n",
    "\n",
    "print(\"*** TRAINING ***\")\n",
    "mlp.fit(train_x, train_y)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(train_x, train_y))      \n",
    "print(\"Test set score:     %f\" % mlp.score(test_x,  test_y))\n",
    "\n",
    "filename = 'mnist_scikit_snn.pkl'\n",
    "print(\"save to %s\" % filename)\n",
    "joblib.dump(mlp, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss curve vs. epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(mlp, ftsize=FONTSIZE):\n",
    "    y    = mlp.loss_curve_\n",
    "    x    = np.array(range(len(y)))+1\n",
    "\n",
    "    ymin = 0.8*min(y)\n",
    "    ymax = 1.2*max(y)\n",
    "    epoch= range(len(y))\n",
    "    xmin = 0\n",
    "    xmax = len(x)\n",
    "    \n",
    "    # set size of figure\n",
    "    plt.figure(figsize=(8,4));\n",
    "\n",
    "    # get axis info\n",
    "    axes = plt.gca()\n",
    "    # set axes' limits\n",
    "    axes.set_xlim(xmin, xmax)\n",
    "    axes.set_ylim(ymin, ymax)\n",
    "    \n",
    "    # annotate axes\n",
    "    plt.xlabel('iteration', fontsize=ftsize)\n",
    "    plt.ylabel('loss',  fontsize=ftsize)\n",
    "    \n",
    "    # choose color of points\n",
    "    plt.plot(x, y, 'b-')\n",
    "    plt.savefig('mnist_scikit_loss.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLoss(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
